{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84ef5809",
   "metadata": {},
   "source": [
    "# Sun Life Machine Learning Engineer - Take Home Assessment\n",
    "\n",
    "This notebook demonstrates an end-to-end solution for an insurance application quoting process.\n",
    "\n",
    "Key deliverables:\n",
    "- Realistic synthetic data generation\n",
    "- BMI calculation\n",
    "- Supervised ML model to approximate BMI\n",
    "- Evaluation on held-out data\n",
    "- Business rule-based quoting logic\n",
    "- Operationalization approach for production deployment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d61546",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1617a278",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, root_mean_squared_error, r2_score\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd93c6ef",
   "metadata": {},
   "source": [
    "## 1. Synthetic Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776c9cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix random seed for reproducibility\n",
    "np.random.seed(30)\n",
    "\n",
    "N = 2000  # Number of synthetic applicants\n",
    "\n",
    "# Create basic demographic attributes\n",
    "application_ids = [f\"APP_{i:05d}\" for i in range(1, N + 1)]\n",
    "genders = np.random.choice([\"Male\", \"Female\"], size=N)\n",
    "ages = np.random.randint(18, 80, size=N)\n",
    "\n",
    "# Height distributions vary slightly by gender to simulate realism\n",
    "heights = []\n",
    "for g in genders:\n",
    "    base_height = np.random.normal(175, 7) if g == \"Male\" else np.random.normal(162, 6)\n",
    "    heights.append(np.clip(base_height, 145, 200))  # Avoid unrealistic extremes\n",
    "\n",
    "heights = np.array(heights)\n",
    "\n",
    "# Generate BMI from a reasonable distribution, then derive weight\n",
    "bmi_values = np.clip(np.random.normal(27, 5, size=N), 15, 45)\n",
    "weights = bmi_values * ((heights / 100) ** 2)\n",
    "\n",
    "# Add small noise to simulate measurement variation\n",
    "weights += np.random.normal(0, 1.5, size=N)\n",
    "\n",
    "# Assemble DataFrame\n",
    "applicants_df = pd.DataFrame({\n",
    "    \"applicationID\": application_ids,\n",
    "    \"gender\": genders,\n",
    "    \"height\": heights,\n",
    "    \"weight\": weights,\n",
    "    \"age\": ages\n",
    "})\n",
    "\n",
    "# Persist dataset\n",
    "applicants_df.to_csv(\"synthetic_insurance_applicants.csv\", index=False)\n",
    "\n",
    "applicants_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56c9b5f",
   "metadata": {},
   "source": [
    "## 2. BMI Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba21498c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_bmi(height_cm: float, weight_kg: float) -> float:\n",
    "    \"\"\"Compute BMI safely using metric formula.\"\"\"\n",
    "    if height_cm <= 0:\n",
    "        return np.nan\n",
    "    height_m = height_cm / 100\n",
    "    return weight_kg / (height_m ** 2)\n",
    "\n",
    "# Apply BMI calculation row-wise\n",
    "applicants_df[\"BMI\"] = applicants_df.apply(\n",
    "    lambda row: calculate_bmi(row[\"height\"], row[\"weight\"]),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "applicants_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e930411",
   "metadata": {},
   "source": [
    "## 3. Machine Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f2a628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature matrix and target\n",
    "X = applicants_df[[\"gender\", \"height\", \"weight\", \"age\"]]\n",
    "y = applicants_df[\"BMI\"]\n",
    "\n",
    "# Split data into train/test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Preprocessing:\n",
    "# - Scale numerical features\n",
    "# - One-hot encode categorical feature (gender)\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), [\"height\", \"weight\", \"age\"]),\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), [\"gender\"])\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Random Forest chosen as a robust default for nonlinear tabular data\n",
    "model = RandomForestRegressor(\n",
    "    n_estimators=200,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Combine preprocessing and model into single pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    (\"preprocessing\", preprocessor),\n",
    "    (\"model\", model)\n",
    "])\n",
    "\n",
    "# Train model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Save trained artifact for reuse\n",
    "joblib.dump(pipeline, \"bmi_prediction_model.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9f892b",
   "metadata": {},
   "source": [
    "## 4. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0498d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions on test data\n",
    "preds = pipeline.predict(X_test)\n",
    "\n",
    "# Compute standard regression metrics\n",
    "mae = mean_absolute_error(y_test, preds)\n",
    "rmse = root_mean_squared_error(y_test, preds)\n",
    "r2 = r2_score(y_test, preds)\n",
    "\n",
    "print(\"Evaluation Metrics (Test Set)\")\n",
    "print(\"MAE :\", round(mae, 4))\n",
    "print(\"RMSE:\", round(rmse, 4))\n",
    "print(\"R2  :\", round(r2, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4a97e7",
   "metadata": {},
   "source": [
    "## 5. Business Rule Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da1d996",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_quote(applicant: pd.Series):\n",
    "    \"\"\"Apply rule-based logic to determine insurance quote.\"\"\"\n",
    "    \n",
    "    age = applicant[\"age\"]\n",
    "    bmi = applicant[\"BMI\"]\n",
    "    gender = applicant[\"gender\"]\n",
    "\n",
    "    # Default quote\n",
    "    quote = 600\n",
    "    reason = \"BMI is in the right range\"\n",
    "\n",
    "    # Age-based rules\n",
    "    if 18 <= age <= 39 and (bmi < 17 or bmi > 37.5):\n",
    "        quote = 800\n",
    "        reason = \"Age is between 18 and 39 and BMI is either less than 17 or greater than 37.5\"\n",
    "\n",
    "    elif 40 <= age <= 59 and (bmi < 18 or bmi > 37.5):\n",
    "        quote = 900\n",
    "        reason = \"Age is between 40 and 59 and BMI is either less than 18 or greater than 37.5\"\n",
    "\n",
    "    elif age > 60 and (bmi < 18 or bmi > 44.5):\n",
    "        quote = 18000\n",
    "        reason = \"Age is greater than 60 and BMI is either less than 18 or greater than 44.5\"\n",
    "\n",
    "    # Gender discount rule\n",
    "    if gender == \"Female\":\n",
    "        quote *= 0.9\n",
    "        reason += \" 10% discount added as application gender is female.\"\n",
    "\n",
    "    return round(quote, 2), reason\n",
    "\n",
    "\n",
    "# Demonstrate logic on sample applicants\n",
    "for _, sample in applicants_df.sample(3, random_state=1).iterrows():\n",
    "    q, r = generate_quote(sample)\n",
    "    print(sample[\"applicationID\"], \"|\", q, \"|\", r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf1c888",
   "metadata": {},
   "source": [
    "## 6. Operationalization Plan\n",
    "\n",
    "If this system were to move beyond a notebook into a production insurance workflow, I would focus on reliability and traceability first, then scalability.\n",
    "\n",
    "### Ingestion & Validation\n",
    "\n",
    "Applications would arrive via API or batch upload. At ingestion:\n",
    "\n",
    "- Validate required fields (applicationID, gender, height, weight, age)\n",
    "- Enforce basic range checks (ex. height > 0, reasonable age limits)\n",
    "- Reject and log invalid records rather than silently correcting them\n",
    "\n",
    "Raw submissions should be stored unchanged in a database or object storage. This ensures every quote decision can be reconstructed later.\n",
    "\n",
    "\n",
    "### Scoring Layer\n",
    "\n",
    "The serialized sklearn Pipeline (preprocessing + model) would be loaded inside a lightweight service layer (ex. FastAPI). Keeping preprocessing inside the pipeline prevents training-serving skew.\n",
    "\n",
    "For each new application:\n",
    "\n",
    "1. Validate inputs  \n",
    "2. Compute BMI (or predict it if required)  \n",
    "3. Pass enriched record to the quoting engine  \n",
    "\n",
    "This keeps model logic isolated from business rules.\n",
    "\n",
    "\n",
    "### Business Rules Engine\n",
    "\n",
    "The rule engine should remain separate from the ML model since pricing rules may change more frequently and may require compliance review.\n",
    "\n",
    "Each quote decision should log:\n",
    "- Input snapshot\n",
    "- Model version\n",
    "- Rule version\n",
    "- Final quote and reason string\n",
    "\n",
    "Model and rule versioning is important for regulatory and audit requirements.\n",
    "\n",
    "\n",
    "### Monitoring & Governance\n",
    "\n",
    "Once deployed, I would monitor:\n",
    "\n",
    "- Input data distribution shifts (age, height, weight)\n",
    "- Quote distribution changes\n",
    "- API latency and failure rates\n",
    "\n",
    "\n",
    "### Testing & Deployment\n",
    "\n",
    "- Unit tests for BMI calculation and rule boundaries  \n",
    "- Integration test for full scoring pipeline  \n",
    "- Version-controlled deployments with rollback capability  \n",
    "\n",
    "Given the lightweight model and workload, horizontal scaling behind a simple API service would be sufficient.\n",
    "\n",
    "This approach keeps the system maintainable, traceable, and production-ready without unnecessary complexity.\n",
    "\n",
    "Thank you for taking the time to review this submission. I appreciate the opportunity to work through this assignment and demonstrate my approach."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
